{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnYechanJo/Novo-Nordisk_Anomaly-Detection/blob/classifier/Final_3_times.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "#Synthetic CNV Image Classifier\n",
        "This notebook uses CNV images from the OCT2017 dataset to generate synthetic CNV images using a Stable Diffusion model. The synthetic images are then mixed with Normal CNV images at various ratios (0% to 100%) to train a classifier. The goal is to find the optimal ratio of synthetic images to maximize classifier performance.\n",
        "\n",
        "Execution Steps:\n",
        "\n",
        "1. Data Preprocessing: OCT2017 CNV/NORMAL images → ViT embeddings → pre-trained_dataset.pt.\n",
        "\n",
        "2. Diffusion Model Fine-tuning: Fine-tune Stable Diffusion UNet with CNV images.\n",
        "\n",
        "3. Synthetic CNV Image Generation: Generate images using the fine-tuned model → ViT embeddings → synthetic_cnv_dataset.pt.\n",
        "\n",
        "4. Classifier Training by Ratio: Mix data at synthetic ratios from 0% to 100% → Train classifier → Compare performance.\n",
        "\n",
        "Execution Environment: Google Colab (GPU, e.g., T4 or A100 recommended)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "##1. Environment Setup and Package Installation\n",
        "Install the required Python packages and set the random seed to ensure reproducibility. GPU will be utilized, and functions for memory management will also be defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install_packages",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5050140-84ca-49f3-add1-d96eb3a0e8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\n",
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub torch torchvision transformers diffusers accelerate datasets xformers pytorch-fid pandas\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from transformers import ViTModel, CLIPTextModel, CLIPTokenizer\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler, StableDiffusionPipeline\n",
        "from accelerate import Accelerator\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_fid import fid_score\n",
        "\n",
        "# Set random seed\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# GPU setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Memory cleanup function\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def img_transform():\n",
        "    return transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.crop((0, 100, 768, 400))),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "def load_trans(path, pic_num=640):\n",
        "    trans_toTensor = img_transform()\n",
        "    image_list = []\n",
        "    i = 0\n",
        "    for filename in os.listdir(path):\n",
        "        if i == pic_num:\n",
        "            break\n",
        "        file_path = os.path.join(path, filename)\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            try:\n",
        "                img = Image.open(file_path).convert(\"RGB\")\n",
        "                tensor_img = trans_toTensor(img)\n",
        "                image_list.append(tensor_img)\n",
        "            except Exception as e:\n",
        "                print(f\"Skip: {filename}, Error: {e}\")\n",
        "        i += 1\n",
        "    return image_list\n",
        "\n",
        "class OCTDataset(Dataset):\n",
        "    def __init__(self, root_dir, label, transform):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
        "        self.label = label\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "        return img, self.label\n",
        "\n",
        "\n",
        "class BalancedBatchSampler(Sampler):\n",
        "    def __init__(self, syn_cnv_len, real_cnv_len, norm_len, batch_size=128, syn_cnv_ratio=0.25, num_batches=30,seed=123):\n",
        "        self.syn_cnv_len = syn_cnv_len\n",
        "        self.real_cnv_len = real_cnv_len\n",
        "        self.norm_len = norm_len\n",
        "        self.batch_size = batch_size\n",
        "        self.syn_cnv_ratio = syn_cnv_ratio\n",
        "        self.num_batches = num_batches\n",
        "        self.seed = seed\n",
        "        self.cnv_batch = batch_size // 2\n",
        "        self.norm_batch = batch_size // 2\n",
        "        self.syn_cnv_batch = int(self.cnv_batch * syn_cnv_ratio)\n",
        "        self.real_cnv_batch = self.cnv_batch - self.syn_cnv_batch\n",
        "\n",
        "        total_syn_needed = self.syn_cnv_batch * num_batches\n",
        "        total_real_cnv_needed = self.real_cnv_batch * num_batches\n",
        "        total_norm_needed = self.norm_batch * num_batches\n",
        "\n",
        "        assert self.syn_cnv_len >= total_syn_needed\n",
        "        assert self.real_cnv_len >= total_real_cnv_needed\n",
        "        assert self.norm_len >= total_norm_needed\n",
        "        rng = random.Random(seed)\n",
        "        self.syn_indices = rng.sample(range(self.syn_cnv_len), total_syn_needed)\n",
        "        self.real_cnv_indices = rng.sample(range(self.real_cnv_len), total_real_cnv_needed)\n",
        "        self.norm_indices = rng.sample(range(self.norm_len), total_norm_needed)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(self.num_batches):\n",
        "            syn_idx = self.syn_indices[i*self.syn_cnv_batch : (i+1)*self.syn_cnv_batch]\n",
        "            real_cnv_idx = self.real_cnv_indices[i*self.real_cnv_batch : (i+1)*self.real_cnv_batch]\n",
        "            norm_idx = self.norm_indices[i*self.norm_batch : (i+1)*self.norm_batch]\n",
        "            yield syn_idx, real_cnv_idx, norm_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "\n",
        "\n",
        "def build_dataloader(syn_dir, cnv_dir, norm_dir, batch_size=128, syn_ratio=0.5):\n",
        "    syn_cnv_dataset = OCTDataset(syn_dir,1,img_transform())\n",
        "    real_cnv_dataset = OCTDataset(cnv_dir,1,img_transform())\n",
        "    norm_dataset = OCTDataset(norm_dir,0,img_transform())\n",
        "\n",
        "    sampler = BalancedBatchSampler(\n",
        "        syn_cnv_len=len(syn_cnv_dataset),\n",
        "        real_cnv_len=len(real_cnv_dataset),\n",
        "        norm_len=len(norm_dataset),\n",
        "        batch_size=batch_size,\n",
        "        syn_cnv_ratio=syn_ratio\n",
        "    )\n",
        "\n",
        "    def collate_fn(index_tuple):\n",
        "        syn_idx, cnv_idx, norm_idx = index_tuple\n",
        "        syn_batch = [syn_cnv_dataset[i] for i in syn_idx]\n",
        "        cnv_batch = [real_cnv_dataset[i] for i in cnv_idx]\n",
        "        norm_batch = [norm_dataset[i] for i in norm_idx]\n",
        "\n",
        "        batch = syn_batch + cnv_batch + norm_batch\n",
        "        random.shuffle(batch)\n",
        "        imgs, labels = zip(*batch)\n",
        "        return torch.stack(imgs), torch.tensor(labels)\n",
        "\n",
        "\n",
        "    dummy_dataset = list(range(len(sampler)))\n",
        "    loader = DataLoader(dummy_dataset, batch_size=1, collate_fn=collate_fn,num_workers=2, pin_memory=True)\n",
        "    return loader\n"
      ],
      "metadata": {
        "id": "uQUaE6nug6Zi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # (3,224,224) -> (16,224,224)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                            # -> (16,112,112)\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # -> (32,112,112)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # -> (32,56,56)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # -> (64,56,56)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)                              # -> (64,28,28)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),             # -> (64×28×28)\n",
        "            nn.Linear(64*28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2)         # 2-class classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = SimpleCNN().cuda()\n",
        "        self.best_acc = 0\n",
        "    def train_val_test(self,syn_dir, cnv_dir, norm_dir):\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay = 1e-4)\n",
        "        # unpack\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        if os.path.exists('Dataset.pt'):\n",
        "         data_dic = torch.load('Dataset.pt')\n",
        "         mixed_val = data_dic['val_data'].to(device)\n",
        "         mixed_val_label = data_dic['val_label'].to(device)\n",
        "         mixed_test = data_dic['test_data'].to(device)\n",
        "         mixed_test_label = data_dic['test_label'].to(device)\n",
        "        train_loader = build_dataloader(syn_dir, cnv_dir, norm_dir)\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "        epochs = 15\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "            # train\n",
        "            self.model.train()\n",
        "            for i, data in enumerate(train_loader):\n",
        "                total = len(train_loader)\n",
        "                batch_x, batch_y = (item.cuda() for item in data)\n",
        "                self.optimizer.zero_grad()\n",
        "                logit_original = self.model(batch_x)\n",
        "                l = loss(logit_original, batch_y)\n",
        "                l.backward()\n",
        "                self.optimizer.step()\n",
        "                corrects = (torch.max(logit_original, 1)[1].view(batch_y.size()).data == batch_y.data).sum()\n",
        "                accuracy = 100 * corrects / len(batch_y)\n",
        "                print(f'Batch[{i + 1}/{total}] - loss: {l.item():.6f}  accuracy: {accuracy:.4f}%({corrects}/{batch_y.size(0)})')\n",
        "            # val\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                logits = self.model(mixed_val)\n",
        "                predicted = torch.max(logits,dim=1)[1]\n",
        "                y_pred = predicted.data.cpu().numpy().tolist()\n",
        "                acc = accuracy_score(mixed_val_label.cpu().numpy().tolist(), y_pred)\n",
        "                print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "                if acc > self.best_acc:\n",
        "                   self.best_acc = acc\n",
        "                print(\"Best val set acc:\", self.best_acc)\n",
        "        # test\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(mixed_test)\n",
        "            predicted = torch.max(logits,dim=1)[1]\n",
        "            y_pred = predicted.data.cpu().numpy().tolist()\n",
        "            try:\n",
        "              res = classification_report(mixed_test_label.cpu().numpy().tolist(), y_pred, labels=[0, 1], target_names=['NR', 'FR'], digits=3, output_dict=True)\n",
        "              for k, v in res.items():\n",
        "                  print(k, v)\n",
        "              print(f\"result: {res['accuracy']:.4f}\")\n",
        "            except ValueError as e:\n",
        "              print(f\"Error in classification_report: {e}\")\n",
        "              res = {'accuracy': 0, 'macro avg': {'f1-score': 0, 'precision': 0, 'recall': 0}}\n",
        "        return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def runable(model,syn_dir, cnv_dir, norm_dir):\n",
        "    nn = model\n",
        "    res = nn.train_val_test(syn_dir, cnv_dir, norm_dir)\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "lSIfFarsI6TL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import kagglehub\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "synthetic_path = \"/content/drive/MyDrive/synthetic_cnv_merged\"\n",
        "\n",
        "def train_classifier_with_ratios():\n",
        "    results = []\n",
        "    # download dataset\n",
        "    path = kagglehub.dataset_download(\"paultimothymooney/kermany2018\")\n",
        "    loadpath = os.path.join(path, \"OCT2017 /train\")\n",
        "    loadpath_1 = os.path.join(path, \"OCT2017 /test\")\n",
        "    train_path_cnv = os.path.join(loadpath, \"CNV\")\n",
        "    train_path_normal = os.path.join(loadpath, \"NORMAL\")\n",
        "    # 120:120 *2\n",
        "    tv_path_cnv = os.path.join(loadpath, \"CNV\")\n",
        "    tv_path_normal = os.path.join(loadpath, \"NORMAL\")\n",
        "    cnv_tensor_list = load_trans(tv_path_cnv, pic_num = 240)\n",
        "    normal_tensor_list = load_trans(tv_path_normal,  pic_num = 240)\n",
        "    cnv_tensor_list = torch.stack(cnv_tensor_list)\n",
        "    normal_tensor_list = torch.stack(normal_tensor_list)\n",
        "    # ratio : 0~1\n",
        "    ratios = [i/10 for i in range(11)]\n",
        "    for ratio in ratios:\n",
        "\n",
        "        #get val dataset\n",
        "        i, j = 0,0\n",
        "        val_labels = torch.cat([torch.ones(120, dtype=torch.long),\n",
        "                              torch.zeros(120, dtype=torch.long)], dim=0)\n",
        "        n_cnv = cnv_tensor_list[i:i+120]\n",
        "        n_norm = normal_tensor_list[j:j+120]\n",
        "        mixed_val = torch.cat([n_cnv, n_norm],dim=0)\n",
        "        print(i)\n",
        "        #get test dataset\n",
        "        i, j=120,120\n",
        "        test_labels = torch.cat([torch.ones(120, dtype=torch.long),\n",
        "                              torch.zeros(120, dtype=torch.long)], dim=0)\n",
        "        n_cnv = cnv_tensor_list[i:i+120]\n",
        "        n_norm = normal_tensor_list[j:j+120]\n",
        "        mixed_test = torch.cat([n_cnv, n_norm],dim=0)\n",
        "\n",
        "        # save norm->0 / cnv->1\n",
        "        if os.path.exists('Dataset.pt'):\n",
        "           os.remove('Dataset.pt')\n",
        "        torch.save({\n",
        "            \"val_data\": mixed_val,\n",
        "            \"val_label\": val_labels,\n",
        "            \"test_data\": mixed_test,\n",
        "            \"test_label\": test_labels\n",
        "        },\"Dataset.pt\")\n",
        "        clear_memory()\n",
        "\n",
        "        # Train and evaluate model\n",
        "        print(f\"Training model with ratio {ratio}\")\n",
        "        model = Classifier()  # Assumes Classifier is defined elsewhere\n",
        "        res = runable(model,synthetic_path,train_path_cnv,train_path_normal)  # Assumes train_and_test is defined\n",
        "        results.append({\n",
        "            'ratio': ratio,\n",
        "            'accuracy': res['accuracy'],\n",
        "            'f1_score': res['macro avg']['f1-score'],\n",
        "            'precision': res['macro avg']['precision'],\n",
        "            'recall': res['macro avg']['recall']\n",
        "        })\n",
        "        clear_memory()  # Assumes clear_memory is defined elsewhere\n",
        "\n",
        "\n",
        "    print(\"\\nResults for Ratio 0 to 1:\")\n",
        "    for res in results:\n",
        "        if res['accuracy'] is not None:\n",
        "            print(f\"Ratio: {res['ratio']*100:.0f}% | Accuracy: {res['accuracy']:.4f} | F1 Score: {res['f1_score']:.4f} | Precision: {res['precision']:.4f} | Recall: {res['recall']:.4f}\")\n",
        "\n",
        "\n",
        "    pd.DataFrame(results).to_csv('classifier_results.csv', index=False)\n",
        "    print(\"Results saved to classifier_results.csv\")\n",
        "\n",
        "train_classifier_with_ratios()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "RjXlu87tI_gy",
        "outputId": "a6e64c78-181d-4bf5-9f66-6eef33fdbc9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'load_trans' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8420a258c24b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results saved to classifier_results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mtrain_classifier_with_ratios\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-8420a258c24b>\u001b[0m in \u001b[0;36mtrain_classifier_with_ratios\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtv_path_cnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CNV\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtv_path_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NORMAL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcnv_tensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv_path_cnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mnormal_tensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv_path_normal\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpic_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcnv_tensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnv_tensor_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_trans' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}