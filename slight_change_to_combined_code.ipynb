{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ14tvwv/4HfmdNdpA8bqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnYechanJo/Novo-Nordisk_Anomaly-Detection/blob/classifier/slight_change_to_combined_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier Training and Result Analysis by Synthetic Data Ratio slight change version"
      ],
      "metadata": {
        "id": "9HO_N_TdqNQK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coI4Aun9qFFI"
      },
      "outputs": [],
      "source": [
        "def train_classifier_with_ratios():\n",
        "    normal_dataset = torch.load('pre-trained_dataset.pt')\n",
        "    synthetic_dataset = torch.load('synthetic_cnv_dataset.pt')\n",
        "\n",
        "    normal_cnv_indices = normal_dataset['label'] == 0\n",
        "    normal_normal_indices = normal_dataset['label'] == 1\n",
        "    normal_cnv_data = {\n",
        "        'data_0': normal_dataset['data_0'][normal_cnv_indices],\n",
        "        'data_1': normal_dataset['data_1'][normal_cnv_indices],\n",
        "        'data_2': normal_dataset['data_2'][normal_cnv_indices],\n",
        "        'data_3': normal_dataset['data_3'][normal_cnv_indices],\n",
        "        'label': normal_dataset['label'][normal_cnv_indices]\n",
        "    }\n",
        "    normal_normal_data = {\n",
        "        'data_0': normal_dataset['data_0'][normal_normal_indices],\n",
        "        'data_1': normal_dataset['data_1'][normal_normal_indices],\n",
        "        'data_2': normal_dataset['data_2'][normal_normal_indices],\n",
        "        'data_3': normal_dataset['data_3'][normal_normal_indices],\n",
        "        'label': normal_dataset['label'][normal_normal_indices]\n",
        "    }\n",
        "    synthetic_cnv_data = synthetic_dataset\n",
        "\n",
        "    ratios = np.arange(0, 1.1, 0.1)\n",
        "    results = []\n",
        "\n",
        "    for ratio in ratios:\n",
        "        print(f\"\\nTraining with Synthetic Ratio: {ratio*100:.0f}%\")\n",
        "        num_synthetic_batch = int(64 * ratio)\n",
        "        num_normal_cnv_batch = 64 - num_synthetic_batch\n",
        "        mixed_data_0 = []\n",
        "        mixed_data_1 = []\n",
        "        mixed_data_2 = []\n",
        "        mixed_data_3 = []\n",
        "        labels_list = []\n",
        "        for i in range(batch_num):\n",
        "            labels = torch.cat([torch.zeros(half_batch, dtype=torch.long), torch.ones(half_batch, dtype=torch.long)], dim=0)\n",
        "            s_cnv_0 = synthetic_cnv_data['data_0'][i*num_synthetic_batch:(i+1)*num_synthetic_batch]\n",
        "            s_cnv_1 = synthetic_cnv_data['data_1'][i*num_synthetic_batch:(i+1)*num_synthetic_batch]\n",
        "            s_cnv_2 = synthetic_cnv_data['data_2'][i*num_synthetic_batch:(i+1)*num_synthetic_batch]\n",
        "            s_cnv_3 = synthetic_cnv_data['data_3'][i*num_synthetic_batch:(i+1)*num_synthetic_batch]\n",
        "            n_cnv_0 = normal_cnv_data['data_0'][i*num_normal_cnv_batch:(i+1)*num_normal_cnv_batch]\n",
        "            n_cnv_1 = normal_cnv_data['data_1'][i*num_normal_cnv_batch:(i+1)*num_normal_cnv_batch]\n",
        "            n_cnv_2 = normal_cnv_data['data_2'][i*num_normal_cnv_batch:(i+1)*num_normal_cnv_batch]\n",
        "            n_cnv_3 = normal_cnv_data['data_3'][i*num_normal_cnv_batch:(i+1)*num_normal_cnv_batch]\n",
        "            n_normal_0 = normal_normal_data['data_0'][i*half_batch:(i+1)*half_batch]\n",
        "            n_normal_1 = normal_normal_data['data_1'][i*half_batch:(i+1)*half_batch]\n",
        "            n_normal_2 = normal_normal_data['data_2'][i*half_batch:(i+1)*half_batch]\n",
        "            n_normal_3 = normal_normal_data['data_3'][i*half_batch:(i+1)*half_batch]\n",
        "            indices = torch.randperm(batch_size)\n",
        "            compose_batch_0 = torch.cat([s_cnv_0,n_cnv_0,n_normal_0],dim=0)\n",
        "            compose_batch_1 = torch.cat([s_cnv_1,n_cnv_1,n_normal_1],dim=0)\n",
        "            compose_batch_2 = torch.cat([s_cnv_2,n_cnv_2,n_normal_2],dim=0)\n",
        "            compose_batch_3 = torch.cat([s_cnv_3,n_cnv_3,n_normal_3],dim=0)\n",
        "            # 128 per batch balance and shuffle\n",
        "            mixed_data_0.append(compose_batch_0[indices])\n",
        "            mixed_data_1.append(compose_batch_1[indices])\n",
        "            mixed_data_2.append(compose_batch_2[indices])\n",
        "            mixed_data_3.append(compose_batch_3[indices])\n",
        "            labels_list.append(labels[indices])\n",
        "\n",
        "        mixed_data_0 = torch.cat(mixed_data_0, dim=0)\n",
        "        mixed_data_1 = torch.cat(mixed_data_1, dim=0)\n",
        "        mixed_data_2 = torch.cat(mixed_data_2, dim=0)\n",
        "        mixed_data_3 = torch.cat(mixed_data_3, dim=0)\n",
        "        mixed_labels = torch.cat(labels_list,dim=0)\n",
        "\n",
        "        x_train = torch.arange(0, 1024)\n",
        "        x_val = torch.arange(1024, 1152)\n",
        "        x_test = torch.arange(1152, 1280)\n",
        "        y_train = mixed_labels[:1024]\n",
        "        y_val = mixed_labels[1024:1152]\n",
        "        y_test = mixed_labels[1152:1280]\n",
        "\n",
        "        # 임베딩 저장\n",
        "        if os.path.exists('pre-trained_dataset.pt'):\n",
        "            os.remove('pre-trained_dataset.pt')\n",
        "        torch.save({\n",
        "            'data_0': mixed_data_0,\n",
        "            'data_1': mixed_data_1,\n",
        "            'data_2': mixed_data_2,\n",
        "            'data_3': mixed_data_3,\n",
        "            'label': mixed_labels\n",
        "        }, 'pre-trained_dataset.pt')\n",
        "\n",
        "        model = Classifier()\n",
        "        res = train_and_test(model, x_train, y_train, x_val, y_val, x_test, y_test)\n",
        "\n",
        "        results.append({\n",
        "            'ratio': ratio,\n",
        "            'accuracy': res['accuracy'],\n",
        "            'f1_score': res['macro avg']['f1-score'],\n",
        "            'precision': res['macro avg']['precision'],\n",
        "            'recall': res['macro avg']['recall']\n",
        "        })\n",
        "        clear_memory()\n",
        "\n",
        "    print(\"\\nResults Summary:\")\n",
        "    for res in results:\n",
        "        print(f\"Ratio: {res['ratio']*100:.0f}% | Accuracy: {res['accuracy']:.4f} | F1 Score: {res['f1_score']:.4f} | Precision: {res['precision']:.4f} | Recall: {res['recall']:.4f}\")\n",
        "\n",
        "    best_result = max(results, key=lambda x: x['accuracy'])\n",
        "    print(f\"\\nBest Ratio: {best_result['ratio']*100:.0f}%\")\n",
        "    print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {best_result['f1_score']:.4f}\")\n",
        "    print(f\"Precision: {best_result['precision']:.4f}\")\n",
        "    print(f\"Recall: {best_result['recall']:.4f}\")\n",
        "\n",
        "    pd.DataFrame(results).to_csv('classifier_results.csv', index=False)\n",
        "    print(\"Results saved to classifier_results.csv\")\n",
        "\n",
        "train_classifier_with_ratios()"
      ]
    }
  ]
}