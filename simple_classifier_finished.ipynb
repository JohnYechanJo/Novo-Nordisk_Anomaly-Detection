{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcngZKs87fgui2ywMBwoZt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnYechanJo/Novo-Nordisk_Anomaly-Detection/blob/classifier/simple_classifier_finished.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "image generation"
      ],
      "metadata": {
        "id": "_AeZWcEX4Qf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VIT Processing\n",
        "def img_transform():\n",
        "    return transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.crop((0, 100, 768, 400))),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    #3，224，224\n",
        "\n",
        "# Images Transfer to Tensors\n",
        "def load_trans(path, pic_num=640):\n",
        "    trans_toTensor = img_transform()\n",
        "    image_list = []\n",
        "    i = 0\n",
        "    for filename in os.listdir(path):\n",
        "        if i == pic_num:\n",
        "            break\n",
        "        file_path = os.path.join(path, filename)\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            try:\n",
        "                img = Image.open(file_path).convert(\"RGB\")\n",
        "                tensor_img = trans_toTensor(img)\n",
        "                image_list.append(tensor_img)\n",
        "            except Exception as e:\n",
        "                print(f\"Skip: {filename}, Error: {e}\")\n",
        "        i += 1\n",
        "    return image_list\n",
        "\n",
        "# Cell 10: Generate Synthetic CNV Images\n",
        "def generate_synthetic_images():\n",
        "    # Load the Base Pipeline from the Original Model\n",
        "    pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "        \"nota-ai/bk-sdm-small\",\n",
        "        torch_dtype=torch.float16,\n",
        "        use_auth_token=False\n",
        "    ).to(device)\n",
        "\n",
        "    # Load the Fine-tuned UNet\n",
        "    unet = UNet2DConditionModel.from_pretrained(\n",
        "        \"/content/models/sd_cnv_finetuned/final_unet\",\n",
        "        torch_dtype=torch.float16\n",
        "    ).to(device)\n",
        "\n",
        "    # Replace the UNet in the Pipeline\n",
        "    pipeline.unet = unet\n",
        "\n",
        "    # Generate Synthetic Images\n",
        "    synthetic_dir = \"/content/synthetic_cnv/\"\n",
        "    os.makedirs(synthetic_dir, exist_ok=True)\n",
        "    num_images = 640\n",
        "    prompt = (\n",
        "     \"OCT scan shows CNV\"\n",
        "    )\n",
        "\n",
        "\n",
        "    for i in range(num_images):\n",
        "        image = pipeline(prompt, num_inference_steps=50).images[0]\n",
        "        image.save(os.path.join(synthetic_dir, f\"synthetic_cnv_{i}.png\"))\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Generated {i}/{num_images} images\")\n",
        "        clear_memory()\n",
        "\n",
        "    # bsz, 3，224，224\n",
        "    synthetic_tensor_list = load_trans(synthetic_dir, pic_num=num_images)\n",
        "\n",
        "\n",
        "    # Save synthetic_cnv_dataset.pt\n",
        "    if os.path.exists('synthetic_cnv_dataset.pt'):\n",
        "        os.remove('synthetic_cnv_dataset.pt')\n",
        "    torch.save(synthetic_tensor_list, 'synthetic_cnv_dataset.pt')\n",
        "    print(\"Synthetic CNV dataset saved to synthetic_cnv_dataset.pt\")\n",
        "\n",
        "generate_synthetic_images()\n",
        "clear_memory()"
      ],
      "metadata": {
        "id": "n6MsPBf-4SMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier"
      ],
      "metadata": {
        "id": "yp0DkPx25wWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unpack\n",
        "data_dic = torch.load('Dataset.pt')\n",
        "mixed_train = data_dic['train_data']\n",
        "mixed_train_label = data_dic['train_label']\n",
        "mixed_val = data_dic['val_data']\n",
        "mixed_val_label = data_dic['val_label']\n",
        "mixed_test = data_dic['test_data']\n",
        "mixed_test_label = data_dic['test_label']\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # (3,224,224) -> (16,224,224)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                            # -> (16,112,112)\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # -> (32,112,112)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # -> (32,56,56)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # -> (64,56,56)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)                              # -> (64,28,28)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),             # -> (64×28×28)\n",
        "            nn.Linear(64*28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2)         # 2-class classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = SimpleCNN()\n",
        "        self.best_acc = 0\n",
        "    def train_val_test(self):\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "        train_loader = DataLoader(TensorDataset(mixed_train, mixed_train_label), batch_size=128, shuffle=True)\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "        epochs = 15\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "            # train\n",
        "            self.model.train()\n",
        "            for i, data in enumerate(train_loader):\n",
        "                total = len(train_loader)\n",
        "                batch_x, batch_y = (item.cuda() for item in data)\n",
        "                self.optimizer.zero_grad()\n",
        "                logit_original = self.model(batch_x)\n",
        "                l = loss(logit_original, batch_y)\n",
        "                l.backward()\n",
        "                self.optimizer.step()\n",
        "                corrects = (torch.max(logit_original, 1)[1].view(batch_y.size()).data == batch_y.data).sum()\n",
        "                accuracy = 100 * corrects / len(batch_y)\n",
        "                print(f'Batch[{i + 1}/{total}] - loss: {l.item():.6f}  accuracy: {accuracy:.4f}%({corrects}/{batch_y.size(0)})')\n",
        "            # val\n",
        "            self.model.val()\n",
        "            with torch.no_grad():\n",
        "                logits = self.model(mixed_val)\n",
        "                predicted = torch.max(logits,dim=1)[1]\n",
        "                y_pred = predicted.data.cpu().numpy().tolist()\n",
        "                acc = accuracy_score(mixed_val_label, y_pred)\n",
        "                print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "                if acc > self.best_acc:\n",
        "                   self.best_acc = acc\n",
        "                print(\"Best val set acc:\", self.best_acc)\n",
        "        # test\n",
        "        self.model.val()\n",
        "        with torch.no_grad():\n",
        "            logit = self.model(mixed_test)\n",
        "            predicted = torch.max(logits,dim=1)[1]\n",
        "            y_pred = predicted.data.cpu().numpy().tolist()\n",
        "            try:\n",
        "              res = classification_report(mixed_test_label, y_pred, labels=[0, 1], target_names=['NR', 'FR'], digits=3, output_dict=True)\n",
        "              for k, v in res.items():\n",
        "                  print(k, v)\n",
        "              print(f\"result: {res['accuracy']:.4f}\")\n",
        "            except ValueError as e:\n",
        "              print(f\"Error in classification_report: {e}\")\n",
        "              res = {'accuracy': 0, 'macro avg': {'f1-score': 0, 'precision': 0, 'recall': 0}}\n",
        "        return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def runable(model):\n",
        "    nn = model\n",
        "    return nn.train_val_test()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ft7Bctft5w8u",
        "outputId": "63c8ca92-4a91-4144-b252-2459a7099a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1ec3c31376a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmixed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmixed_train_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmixed_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train val and test with ratio"
      ],
      "metadata": {
        "id": "AGdrSo7M5zqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "def train_classifier_with_ratios():\n",
        "    synthetic_images = torch.load('synthetic_cnv_dataset.pt')\n",
        "    path = kagglehub.dataset_download(\"paultimothymooney/kermany2018\")\n",
        "    loadpath = os.path.join(path, \"OCT2017 /train\")\n",
        "    train_path_cnv = os.path.join(loadpath, \"CNV\")\n",
        "    train_path_normal = os.path.join(loadpath, \"NORMAL\")\n",
        "    # bsz,3,224,224\n",
        "    cnv_tensor_list = load_trans(train_path_cnv, pic_num = 800)\n",
        "    normal_tensor_list = load_trans(train_path_normal,  pic_num = 800)\n",
        "    # ratio : 10%~90%\n",
        "    ratios = [i/10 for i in range(1, 10)]\n",
        "    # batch_size = 128\n",
        "    half_batch = 64\n",
        "    batch_num = 10\n",
        "    for ratio in ratios:\n",
        "        mixed_train = []\n",
        "        mixed_train_label = []\n",
        "        num_synthetic_batch = int(64 * ratio)\n",
        "        num_normal_cnv_batch = 64 - num_synthetic_batch\n",
        "\n",
        "        # get train dataset\n",
        "        for i in range(batch_num):\n",
        "          labels = torch.cat([torch.ones(half_batch, dtype=torch.long),\n",
        "                              torch.zeros(half_batch, dtype=torch.long)], dim=0)\n",
        "          s_cnv = synthetic_images[i*num_synthetic_batch:(i+1)*num_synthetic_batch]\n",
        "          n_cnv = cnv_tensor_list[i*num_normal_cnv_batch:(i+1)*num_normal_cnv_batch]\n",
        "          n_norm = normal_tensor_list[i*half_batch:(i+1)*half_batch]\n",
        "          mixed_train.extend([s_cnv, n_cnv, n_norm])\n",
        "          mixed_train_label.append(labels)\n",
        "        mixed_train = torch.cat(mixed_train, dim=0)\n",
        "        mixed_train_label = torch.cat(mixed_train_label, dim=0)\n",
        "\n",
        "        #get val dataset\n",
        "        i, j = batch_num*num_normal_cnv_batch, batch_num*half_batch\n",
        "        val_labels = torch.cat([torch.ones(80, dtype=torch.long),\n",
        "                              torch.zeros(80, dtype=torch.long)], dim=0)\n",
        "        n_cnv = cnv_tensor_list[i:i+80]\n",
        "        n_norm = normal_tensor_list[i:i+80]\n",
        "        mixed_val = torch.cat([n_cnv, n_norm],dim=0)\n",
        "\n",
        "        #get test dataset\n",
        "        i, j=i+80, j+80\n",
        "        test_labels = torch.cat([torch.ones(80, dtype=torch.long),\n",
        "                              torch.zeros(80, dtype=torch.long)], dim=0)\n",
        "        n_cnv = cnv_tensor_list[i:i+80]\n",
        "        n_norm = normal_tensor_list[i:i+80]\n",
        "        mixed_test = torch.cat([n_cnv, n_norm],dim=0)\n",
        "\n",
        "        # save norm->0 / cnv->1\n",
        "        if os.path.exists('pre-trained_dataset.pt'):\n",
        "           os.remove('pre-trained_dataset.pt')\n",
        "        torch.save({\n",
        "            \"train_data\": mixed_train,\n",
        "            \"train_label\": mixed_train_label,\n",
        "            \"val_data\": mixed_val,\n",
        "            \"val_label\": val_labels,\n",
        "            \"test_data\": mixed_test,\n",
        "            \"test_label\": test_labels\n",
        "        },\"Dataset.pt\")\n",
        "\n",
        "\n",
        "        # Train and evaluate model\n",
        "        model = Classifier()  # Assumes Classifier is defined elsewhere\n",
        "        res = runable(model)  # Assumes train_and_test is defined\n",
        "        results.append({\n",
        "            'ratio': ratio,\n",
        "            'accuracy': res['accuracy'],\n",
        "            'f1_score': res['macro avg']['f1-score'],\n",
        "            'precision': res['macro avg']['precision'],\n",
        "            'recall': res['macro avg']['recall']\n",
        "        })\n",
        "        clear_memory()  # Assumes clear_memory is defined elsewhere\n",
        "\n",
        "\n",
        "    print(\"\\nResults for Ratio 10% to 90%:\")\n",
        "    for res in results:\n",
        "        if res['accuracy'] is not None:\n",
        "            print(f\"Ratio: {res['ratio']*100:.0f}% | Accuracy: {res['accuracy']:.4f} | F1 Score: {res['f1_score']:.4f} | Precision: {res['precision']:.4f} | Recall: {res['recall']:.4f}\")\n",
        "\n",
        "\n",
        "    pd.DataFrame(results).to_csv('classifier_results.csv', index=False)\n",
        "    print(\"Results saved to classifier_results.csv\")\n",
        "\n",
        "train_classifier_with_ratios()"
      ],
      "metadata": {
        "id": "LmrfCYR650JI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}