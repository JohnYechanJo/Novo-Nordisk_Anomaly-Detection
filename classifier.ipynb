{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJNAy2g8bdyr",
        "outputId": "9d8ab36b-761f-453f-e263-16217b0e9d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\n",
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub torch torchvision transformers diffusers accelerate datasets xformers pytorch-fid pandas\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from transformers import ViTModel, CLIPTextModel, CLIPTokenizer\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler, StableDiffusionPipeline\n",
        "from accelerate import Accelerator\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import kagglehub\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Set random seed\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# GPU setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Memory cleanup function\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Prepare training images"
      ],
      "metadata": {
        "id": "-K4fhnNobpOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_images():\n",
        "    # Kaggle dataset download\n",
        "    path = kagglehub.dataset_download(\"paultimothymooney/kermany2018\")\n",
        "    print(f\"Dataset downloaded to: {path}\")\n",
        "\n",
        "    # Set dataset path and copy trainset CNV images\n",
        "    in_dir = os.path.join(path, \"OCT2017 /train/CNV\")\n",
        "    out_dir = \"/content/processed/CNV/\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    for fn in os.listdir(in_dir):\n",
        "        img = Image.open(os.path.join(in_dir, fn)).convert(\"RGB\")\n",
        "        img = img.resize((512, 512), resample=Image.LANCZOS)\n",
        "        img.save(os.path.join(out_dir, fn))\n",
        "    print(f\"Processed CNV images saved to {out_dir}\")\n",
        "\n",
        "    # set dataset path and copy trainset Normal images\n",
        "    in_dir = os.path.join(path, \"OCT2017 /train/NORMAL\")\n",
        "    out_dir = \"/content/processed/Normal/\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    for fn in os.listdir(in_dir):\n",
        "        img = Image.open(os.path.join(in_dir, fn)).convert(\"RGB\")\n",
        "        img = img.resize((512, 512), resample=Image.LANCZOS)\n",
        "        img.save(os.path.join(out_dir, fn))\n",
        "    print(f\"Processed CNV images saved to {out_dir}\")\n",
        "\n",
        "    # set dataset path and copy testset CNV images\n",
        "    in_dir = os.path.join(path, \"OCT2017 /test/CNV\")\n",
        "    out_dir = \"/content/testset/CNV/\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    for fn in os.listdir(in_dir):\n",
        "        img = Image.open(os.path.join(in_dir, fn)).convert(\"RGB\")\n",
        "        img = img.resize((512, 512), resample=Image.LANCZOS)\n",
        "        img.save(os.path.join(out_dir, fn))\n",
        "    print(f\"Processed CNV test images saved to {out_dir}\")\n",
        "\n",
        "    # set dataset path and copy testset Normal images\n",
        "    in_dir = os.path.join(path, \"OCT2017 /test/NORMAL\")\n",
        "    out_dir = \"/content/testset/Normal/\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    for fn in os.listdir(in_dir):\n",
        "        img = Image.open(os.path.join(in_dir, fn)).convert(\"RGB\")\n",
        "        img = img.resize((512, 512), resample=Image.LANCZOS)\n",
        "        img.save(os.path.join(out_dir, fn))\n",
        "    print(f\"Processed CNV images saved to {out_dir}\")\n",
        "\n",
        "\n",
        "prepare_images()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A75GKPwbsS8",
        "outputId": "6b3e7668-853c-4c88-df34-37da7db7b1fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /kaggle/input/kermany2018\n",
            "Processed CNV images saved to /content/processed/CNV/\n",
            "Processed CNV images saved to /content/processed/Normal/\n",
            "Processed CNV test images saved to /content/testset/CNV/\n",
            "Processed CNV images saved to /content/testset/Normal/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Classifier and Dataset"
      ],
      "metadata": {
        "id": "Ko4JLqxcb5O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "\n",
        "    def __init__(self, normal_root_dir:str, cnv_root_dir:str, synthetic_root_dir:str = None, ratio:float = 0.0, resolution=512, random_state = 42) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((resolution, resolution), transforms.InterpolationMode.LANCZOS),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5]),\n",
        "        ])\n",
        "\n",
        "        normal_imgs = [\n",
        "            os.path.join(normal_root_dir, f)\n",
        "            for f in os.listdir(normal_root_dir)\n",
        "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
        "        ]\n",
        "\n",
        "        cnv_imgs = [\n",
        "            os.path.join(cnv_root_dir, f)\n",
        "            for f in os.listdir(cnv_root_dir)\n",
        "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
        "        ]\n",
        "\n",
        "        if synthetic_root_dir is not None:\n",
        "\n",
        "          real_img_size = len(cnv_imgs) + len(normal_imgs)\n",
        "\n",
        "          synthetic_imgs = [\n",
        "              os.path.join(synthetic_root_dir, f)\n",
        "              for f in os.listdir(synthetic_root_dir)\n",
        "              if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
        "          ]\n",
        "\n",
        "          synthetic_imgs = shuffle(synthetic_imgs, random_state=random_state)[:int(real_img_size * ratio/(1-ratio))]\n",
        "\n",
        "          self.imgs = normal_imgs + cnv_imgs + synthetic_imgs\n",
        "          self.labels = [0] * len(normal_imgs) + [1] * len(cnv_imgs) + [1] * len(synthetic_imgs)\n",
        "\n",
        "        else:\n",
        "\n",
        "          self.imgs = normal_imgs + cnv_imgs\n",
        "          self.labels = [0] * len(normal_imgs) + [1] * len(cnv_imgs)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx:int) -> tuple:\n",
        "\n",
        "        img = Image.open(self.imgs[idx]).convert(\"L\")\n",
        "        img = self.transform(img)\n",
        "        lbl = self.labels[idx]\n",
        "\n",
        "        return img, lbl\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=\"same\")\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=\"same\")\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 64 * 32, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "\n",
        "        return x.squeeze(1)"
      ],
      "metadata": {
        "id": "aztUp9Nqb8yP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Classifier Training and Validation based on Synthetic Ratio"
      ],
      "metadata": {
        "id": "vaTudi1udCNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_with_ratios():\n",
        "\n",
        "    # Define batch parameters\n",
        "    batch_size = 128\n",
        "    normal_root_dir = \"/content/processed/Normal/\"\n",
        "    cnv_root_dir = \"/content/processed/CNV/\"\n",
        "    synthetic_root_dir = \"/content/synthetic_cnv/\"\n",
        "    resolution = 512\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_epochs = 100\n",
        "\n",
        "    ratios = np.arange(0, 1.1, 0.1)\n",
        "    results = []\n",
        "\n",
        "    os.makedirs(\"classifiers\", exist_ok=True)\n",
        "\n",
        "    for ratio in ratios:\n",
        "\n",
        "        # Train and evaluate model\n",
        "        model = Classifier()  # Assumes Classifier is defined elsewhere\n",
        "        dataset = ClassifierDataset(normal_root_dir, cnv_root_dir, synthetic_root_dir, ratio, resolution, random_state=seed)\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers=4)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory = True, num_workers=4)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            for images, labels in train_loader:\n",
        "\n",
        "                images = images.to(device)\n",
        "                labels = labels.float().to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        for images, labels in val_loader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                outputs = model(images)\n",
        "                y_pred.extend(outputs.cpu().numpy())\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        precision = precision_score(y_true, y_pred, average='macro')\n",
        "        recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "\n",
        "        results.append({\n",
        "            'ratio': ratio,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_score': f1,\n",
        "            'precision': precision,\n",
        "            'recall': recall\n",
        "        })\n",
        "        clear_memory()  # Assumes clear_memory is defined elsewhere\n",
        "\n",
        "        torch.save(model.state_dict(), f\"classifiers/model_ratio_{ratio}.pth\")\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nValidation Results Summary:\")\n",
        "    for res in results:\n",
        "        print(f\"Ratio: {res['ratio']*100:.0f}% | Accuracy: {res['accuracy']:.4f} | F1 Score: {res['f1_score']:.4f} | Precision: {res['precision']:.4f} | Recall: {res['recall']:.4f}\")\n",
        "\n",
        "    best_result = max(results, key=lambda x: x['accuracy'])\n",
        "    print(f\"\\nBest Ratio: {best_result['ratio']*100:.0f}%\")\n",
        "    print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {best_result['f1_score']:.4f}\")\n",
        "    print(f\"Precision: {best_result['precision']:.4f}\")\n",
        "    print(f\"Recall: {best_result['recall']:.4f}\")\n",
        "\n",
        "    # Save results to CSV\n",
        "    pd.DataFrame(results).to_csv('val_classifier_results.csv', index=False)\n",
        "    print(\"Results saved to val_classifier_results.csv\")\n",
        "\n",
        "# Run the function\n",
        "train_classifier_with_ratios()"
      ],
      "metadata": {
        "id": "KLQv_HDfdFsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Apply Models to Testset"
      ],
      "metadata": {
        "id": "mkHPyD85dKG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_classifier_with_ratios():\n",
        "\n",
        "    # Define batch parameters\n",
        "    batch_size = 128\n",
        "    normal_root_dir = \"/content/testset/Normal/\"\n",
        "    cnv_root_dir = \"/content/testset/CNV/\"\n",
        "\n",
        "    resolution = 512\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_epochs = 100\n",
        "\n",
        "    ratios = np.arange(0, 1.1, 0.1)\n",
        "    results = []\n",
        "\n",
        "    os.makedirs(\"classifiers\", exist_ok=True)\n",
        "\n",
        "    for ratio in ratios:\n",
        "\n",
        "        # Load trained model\n",
        "        model = Classifier()\n",
        "        model = model.load_state_dict(torch.load(f\"classifiers/model_ratio_{ratio}.pth\"))\n",
        "\n",
        "        dataset = ClassifierDataset(normal_root_dir, cnv_root_dir, synthetic_root_dir = None, ratio = 0.0, resolution = resolution, random_state=seed)\n",
        "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, pin_memory = True, num_workers=4)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        for images, labels in loader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                outputs = model(images)\n",
        "                y_pred.extend(outputs.cpu().numpy())\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        precision = precision_score(y_true, y_pred, average='macro')\n",
        "        recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "\n",
        "        results.append({\n",
        "            'ratio': ratio,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_score': f1,\n",
        "            'precision': precision,\n",
        "            'recall': recall\n",
        "        })\n",
        "        clear_memory()  # Assumes clear_memory is defined elsewhere\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nTest Results Summary:\")\n",
        "    for res in results:\n",
        "        print(f\"Ratio: {res['ratio']*100:.0f}% | Accuracy: {res['accuracy']:.4f} | F1 Score: {res['f1_score']:.4f} | Precision: {res['precision']:.4f} | Recall: {res['recall']:.4f}\")\n",
        "\n",
        "    best_result = max(results, key=lambda x: x['accuracy'])\n",
        "    print(f\"\\nBest Ratio: {best_result['ratio']*100:.0f}%\")\n",
        "    print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {best_result['f1_score']:.4f}\")\n",
        "    print(f\"Precision: {best_result['precision']:.4f}\")\n",
        "    print(f\"Recall: {best_result['recall']:.4f}\")\n",
        "\n",
        "    # Save results to CSV\n",
        "    pd.DataFrame(results).to_csv('test_classifier_results.csv', index=False)\n",
        "    print(\"Results saved to test_classifier_results.csv\")\n",
        "\n",
        "# Run the function\n",
        "train_classifier_with_ratios()"
      ],
      "metadata": {
        "id": "ztVwvu1Fd7XJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}